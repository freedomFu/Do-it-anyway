# Static Program Analysis - Data Flow Analysis - Foundations

## Iterative Algorithm, Another View

This general iterative algorithm produces a solution to data flow analysis.

### Iterative Algorithm for May & Forward Analysis

**INPUT:** CFG ($kill_B$ and $gen_B$ computed for each basic block B)
**OUTPUT:** IN[B] and OUT[B] for each basic block B
**METHOD:** 

```java
OUT[entry] = âŒ€;
for (each basic block B\entry)
    OUT[B] = âŒ€;
while (changes to any OUT occur)
    for (each basic block B\entry) {
        IN[B] = â‹ƒ _ {P a predecessor of B} OUT[P];
        OUT[B] = gen_B â‹ƒ (IN[B] - kill_B)
    }
```

### View Iterative Algorithm in Another Way

**æ–‡å­—æè¿°ç‰ˆ**

- Given a CFG (program) with **k** nodes, the iterative algorithm updates OUT[n] for every node n in each iteration.
- Assume the domain of the values in data flow analysis is V, then we can define a k-tuple $(OUT[n_1], OUT[n_2], ..., OUT[n_k])$ as an element of set $(V_1 * V_2 * ... * V_k)$ denoted as $V^k$, to hold the values of the analysis after each iteration.
- Each iteration can be considered as taking an action to map an element of $V^k$, through applying the transfer functions and control-flow handling, abstracted as a function $F: V^k â†’ V^k$
- Then the algorithm outputs a series of k-tuples iteratively until a k-tuple is the same as the last one in two consecutive iterations. 

**å›¾ç¤ºç‰ˆ**

Each iteration takes an action $F: V^k â†’ V^k$

![](./figs/04_iterative_pic1.png)

- åˆå§‹åŒ–çš„æ¯ä¸€ä¸ª out åˆå§‹åŒ–ä¸º ç©º âŠ¥
- è¿­ä»£è‡³ï¼ŒæŸä¸€æ¬¡çš„ç»“æœä¸ä¸Šä¸€æ¬¡è¿­ä»£çš„ç»“æœç›¸åŒ
- $X_i = X_{i+1} = F(X_i)$ å…¶ä¸­ X is a **fixed point** of function F if $X = F(X)$ ä¸åŠ¨ç‚¹
- åœ¨è¾¾åˆ°ä¸åŠ¨ç‚¹æ—¶ï¼Œå³ The iterative algorithm reaches **a fixed point**

**The iterative algorithm (or the IN/OUT equation system) produces a solution to a data flow analysis:**

- Is the algorithm guaranteed to terminate or reach the fixed point, or does it always have a solution?
- If so, is there only one solution or only one fixed point? If more than one, is our solution the best one (most precise)?
- When will the algorithm reach the fixed point, or when can we get the solution?

## Math Foundations

### Partial Order ååºé›† 

We define **poset** as a pair (P, âŠ‘) where **âŠ‘** is a binary relation that defines a **partial ordering** over P, and âŠ‘ has the following properties:

(1) âˆ€ x âˆˆ P, x âŠ‘ x                      (Reflexivity è‡ªåæ€§)
(2) âˆ€ x, y âˆˆ P, x âŠ‘ y âˆ§ y âŠ‘ x â‡’ x = y   (Antisymmtry åå¯¹ç§°æ€§)
(3) âˆ€ x, y, z âˆˆ P, x âŠ‘ y âˆ§ y âŠ‘ z â‡’ x âŠ‘ z

**Example 1.** Is (S, âŠ‘) a poset where S is a set of integers and âŠ‘ represents â‰¤ (less than or equal to)?

(1) Reflexivity 1 â‰¤ 1, 2 â‰¤ 2                âœ…
(2) Antisymmtry x â‰¤ y âˆ§ y â‰¤ x then x = y    âœ…
(3) Transitivity 1 â‰¤ 2 âˆ§ 2 â‰¤ 3 then 1 â‰¤ 3   âœ…

å› æ­¤æ˜¯ååºé›†

**Example 2.** Is (S, âŠ‘) a poset where S is a set of integers and âŠ‘ represents ï¼œ (less than)?

(1) Reflexivity 1 ï¼œ 1, 2 ï¼œ 2                â  å› æ­¤ä¸æ˜¯ååºé›†

**Example 3.** Is (S, âŠ‘) a poset where S is a set of English words and âŠ‘ represents the substring relation, i.e., s1 âŠ‘ s2 means s1 is substring of s2? å‡æ»¡è¶³ï¼Œä¹Ÿæ˜¯åŒæ ·çš„å±æ€§

**å¦‚ä½•ç†è§£ååºï¼Ÿ** **partial** means for a pair of set elements in P, they could be **incomparable;** in other words, not necessary that every pair of set elements must satisfy the ordering âŠ‘   å³å¹¶éæ¯ä¸¤ä¸ªå…ƒç´ ä¸ä¸€å®šæœ‰ååºå…³ç³»

> partial çš„å«ä¹‰å¯ä»¥ç†è§£ä¸ºï¼šincomparable 

**Example 4.** Is (S, âŠ‘) a poset where S is the power set of set {a, b, c} and âŠ‘ represents âŠ† (subset)?

å¹‚é›†çš„æ¦‚å¿µï¼Œä¹Ÿæ˜¯æ»¡è¶³çš„ã€‚

![](./figs/04_power_set.png)

### Upper and Lower Bounds 

Given a poset (P, âŠ‘) and its subset S that S âŠ† P, we say that u âˆˆ P is an *upper bound* of S, if âˆ€ x âˆˆ S, x âŠ‘ u. Similarly, l âˆˆ P is a *lower bound* of S, if âˆ€ x âˆˆ S, l âŠ‘ x.

åœ¨ä¸‹å›¾ä¸­ï¼Œç°è‰²éƒ¨åˆ†çš„ upper bound å’Œ lower bound åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ

![](./figs/04_upper_lower_bound.png)

We define the *least upper bound* (lub or join) of S, written â¨†S, if for every upper bound of S, say u, â¨†S âŠ‘ u. Similarly, we define the *greast lower bound* (glb or meet) of S, written â¨…S, if for every lower bound of S, say l, l âŠ‘ â¨…S.

<u>upper boundå’Œlower boundå¯èƒ½å­˜åœ¨å¤šä¸ª</u>

![](./figs/04_lub_glb.png)

Usually, if S contains only two elements a and b (S = {a, b}), then 

- â¨†S can be written a â¨† b (the *join* of a and b)
- â¨…S can be wtitten a â¨… b (the *meet* of a and b)

### Some properties 

- Not every poset has *lub* or *glb*

![](./figs/04_not_all_glb.png)

- But if a poset has *lub* or *glb*, it will be unique

*Proof.*

assume $g_1$ and $g_2$ are both glbs of poset P, according to the definition of glb, thus: $g_1$ âŠ‘ ($g_2$ = â¨…P) and $g_2$ âŠ‘ ($g_1$ = â¨…P) by the antisymmetry of partial order âŠ‘, thus $g_1$ = $g_2$

## Lattice, Semilattice, Complete and Product Lattice

### Lattice æ ¼

Given a poset (P, âŠ‘), âˆ€ a, b âˆˆ P, if a â¨† b and a â¨… b exist, then (P, âŠ‘) is called a lattice.

> A poset is a lattice if **every pair** of its elements has a least upper bound and a greatest lower bound?

**Example 1.** Is (S, âŠ‘) a lattice where S is a set of integers and âŠ‘ represents â‰¤ (less than or equal to)?

The â¨† operator means "max" and â¨… operator means "min". YES

**Example 2.** Is (S, âŠ‘) a lattice where S is a set of English words and âŠ‘ represents the substring relation, i.e., s1 âŠ‘ s2 means s1 is substring of s2?

NO. pin â¨† sin = ? è¿™ä¸ªæ²¡æœ‰ä¸Šç•Œï¼Œå› æ­¤ä¸€å®šä¸æ˜¯

**Example 3.** Is (S, âŠ‘) a lattice where S is the power set of set {a, b, c} and âŠ‘ represents âŠ† (subset)?

The â¨† operator means âˆª and â¨… operator means âˆ©. YES

### Semilattice

Given a poset (P, âŠ‘), âˆ€ a, b âˆˆ P, if only a â¨† b exists, then (P, âŠ‘) is called a join semilattice; if only a â¨… b exists, then (P, âŠ‘) is called a meet semilattice.

### Complete Lattice 

Given a lattice (P, âŠ‘), for arbitrary subset S of P, if â¨†S and â¨…S exist, then (P, âŠ‘) is called a complete lattice.

**All subsets** of a lattice have a least upper bound and a greatest lower bound.

**Example 1.** Is (S, âŠ‘) a complete lattice where S is a set of integers and âŠ‘ represents â‰¤ (less than or equal to)?

For a subset $S^+$ including all positive integers, it has no â¨†$S^+$ (+âˆ)ï¼Œå› æ­¤ä¸æ˜¯

**Example 2.** Is (S, âŠ‘) a complete lattice where S is the power set of set {a, b, c} and âŠ‘ represents âŠ† (subset)?

**Note:** the definition of bounds implies that the bounds are not necessarily in the subsets (but they must be in the lattice). è¾¹ç•Œä¸ä¸€å®šåœ¨å­é›†ä¸­ï¼Œä½†æ˜¯ä¸€å®šéœ€è¦åœ¨ lattice ä¸­

Every complete lattice (P, âŠ‘) has 

- a **greatest** element âŠº = â¨†P called **top** and
- a **least** element âŠ¥ = â¨…P called **bottom**

Every **finite** lattice (P is finite) is a complete lattice.

ä¸€èˆ¬æƒ…å†µä¸‹ complete lattice éƒ½æ˜¯ **æœ‰ç©·** çš„ï¼Œç”¨äºæ•°æ®æµåˆ†æ

### Product Lattice

Given lattices $L_1=(P_1,âŠ‘_1)$, $L_2=(P_2,âŠ‘_2)$, ..., $L_n=(P_n,âŠ‘_n)$, if for all i, $(P_i,âŠ‘_i)$ has $â¨†_i$ (least upper bound) and $â¨…_i$ (greatest lower bound), then we can have a **product lattice** $L^n=(P, âŠ‘)$ that is defined by:

- $P=P_1 * ... * P_n$
- $(x_1,...,x_n)$ âŠ‘ $(y_1,...,y_n)$ â‡” $(x_1âŠ‘y_1)$ âˆ§ ... âˆ§ $(x_nâŠ‘y_n)$
- $(x_1,...,x_n)$ â¨† $(y_1,...,y_n)$ = ($(x_1 â¨†_1 y_1)$, ..., $(x_n â¨†_n y_n)$)
- $(x_1,...,x_n)$ â¨… $(y_1,...,y_n)$ = ($(x_1 â¨…_1 y_1)$, ..., $(x_n â¨…_n y_n)$)

**ä¸¤ä¸ªæ€§è´¨**

- A product lattice is a lattice
- If a product lattice L is a product of complete lattices, then L is also complete

## Data Flow Analysis Framework via Lattice

A data flow analysis framework (D, L, F) consists of:

- **D:** a direction of data flow: forwards or backwards
- **L:** a lattice including domain of the values V and a meet â¨… (intersection) or join â¨† (union) operator
- **F:** a family of transfer functions from V to V

![](./figs/04_dfa_lattice.png)

Data flow analysis can be seen iteratively applying transfer functions and meet/join operations on the values of a lattice.

### Review above questions

- Is the algorithm guaranteed to terminate or reach the fixed point, or does it always have a solution?
  - Recall `OUT never shrinks`. It is about monotonicity.
- If so, is there only one solution or only one fixed point? If more than one, is our solution the best one (most precise)?
  - å¯ä»¥ï¼Œ$f(x)=x^2$ï¼Œå°±æœ‰ä¸¤ä¸ª0 å’Œ 1ï¼Œå› æ­¤æ˜¯ä¸€å®šæœ‰çš„
  - é‚£ä¹ˆæ˜¯ä¸æ˜¯æœ€å¥½çš„å‘¢ï¼Ÿæ˜¯çš„ï¼Œè¦ä¹ˆæ˜¯ greatest fixed pointï¼Œè¦ä¹ˆæ˜¯ least fixed point

## Monotonicity and Fixed Point Theorem

**Monotonicity**

A function f: L â†’ L (L is a lattice) is monotonic if âˆ€ x, y âˆˆ L, x âŠ‘ y â‡’ f(x) âŠ‘ f(y)

**Fixed-Point Theorem**

Given a complete lattice (L, âŠ‘), if: (1) f: L â†’ L is monotonic and (2) L is finite, then 

- the **least fixed point** of f can be found by iterating $f(âŠ¥), f(f(âŠ¥)), ..., f^k(âŠ¥)$ until a fixed point is reached.
- the **greatest fixed point** of f can be found by iterating $f(âŠº), f(f(âŠº)), ..., f^k(âŠº)$ until a fixed point is reached.

### Fixed-Point Theorem (Existence of Fixed Point)

*Proof:*

By the definition of âŠ¥ and f: L â†’ L, we have: âŠ¥ âŠ‘ f(âŠ¥)

As f is monotonic, we have: f(âŠ¥) âŠ‘ f(f(âŠ¥)) = $f^2(âŠ¥)$

Similarly (by repeated applying f), we have:

âŠ¥ âŠ‘ f(âŠ¥) âŠ‘ $f^2(âŠ¥)$ âŠ‘ ... âŠ‘ $f^i(âŠ¥)$

As L is finite, for some k, we have: $f^{Fix} = f^k(âŠ¥) = f^{k+1}(âŠ¥)$

Thus, the fixed point exists.

### Fixed-Point Theorem (Least Fixed Point)

*Proof:*

Assume we have another fixed point x, i.e., x = f(x) 

By the definition of âŠ¥, we have âŠ¥ âŠ‘ x

Induction begins: æ•°å­¦å½’çº³æ³•

As f is monotonic, we have f(âŠ¥) âŠ‘ f(x)

Assume $f^i(âŠ¥) âŠ‘ f^i (x)$, as f is monotonic, we have: $f^{i+1}(âŠ¥) âŠ‘ f^{i+1} (x)$

Thus by induction, we have $f^{i}(âŠ¥) âŠ‘ f^{i} (x) = x$, then we have: $f_{Fix} = f^k(âŠ¥) âŠ‘ x$

Thus the fixed point is the least.

**Now** what we have just seen is the property (fixed point theorem) for the function on a lattice. We cannot say our iterative algorithm also has that property unless we can *relate the algorithm to the fixed point theorem*, if possible.

## Relate Iterative Algorithm to Fixed Point Theorem (åå‘äºç›´è§‚çš„æè¿°)

1. é¦–å…ˆï¼Œå¯ä»¥å‘ç°æ¯ä¸€ä¸ªLéƒ½æ˜¯ complete ä¸” finite çš„ lattice ï¼Œå› æ­¤å¾—åˆ°çš„ product latticeä¹Ÿæ˜¯ complete ä¸” finite çš„
2. å¦å¤–ï¼Œå¯ä»¥æŠŠæ¯ä¸€æ¬¡è½¬æ¢çœ‹ä½œæ˜¯ä¸¤ä¸ªæµç¨‹ä¹‹é—´é‡‡ç”¨äº† Transfer Functionï¼Œå¹¶ä¸”åº”ç”¨äº† meet æˆ–è€… join çš„æ“ä½œ
3. æ¥ä¸‹æ¥ï¼Œéœ€è¦è¯æ˜ Now the remaining issue is to prove the **function F** is monotonic

![](./figs/04_relate_algorithm_to_theorem.png)

### Prove Function F is Monotonic 

In each iteration, it is equivalent to think that we apply function F which consists of:

(1) transfer function $f_i: L â†’ L$ for every node
   - æœ‰æåˆ°è¿‡æ‰€æœ‰çš„ Never shrinks ï¼Œæ‰€æœ‰çš„ Transfer Function éƒ½æ˜¯ monotonic; Gen/Kill function is monotonic 

(2) join/meet function $â¨†/â¨…: L * L â†’ L$ for control-flow confluence
   - Actually the binary operator is a basic case of L * L * ... * L ï¼Œå› æ­¤åªéœ€è¦è¯æ˜ basic case æ˜¯å•è°ƒå³å¯

**è¯æ˜ â¨† æ˜¯å•è°ƒçš„**

âˆ€ x, y, z âˆˆ L, x âŠ‘ y, we wan to prove x â¨† z âŠ‘ y â¨† z

by the definition of â¨†, y âŠ‘ y â¨† z

by transitivity of âŠ‘, x âŠ‘ y â¨† z

thus y â¨† z is an upper bound for x, and also for z (by â¨†'s definition)

as x â¨† z is the least upper bound of x and z 

thus x â¨† z âŠ‘ y â¨† z

**Thus the fixed point theorem applies to the iterative algorithm for data flow analysis**

Now what we have just seen is the property (fixed point theorem) for the function on a lattice. We can *relate the algorithm to the fixed point theorem*.

### When Will the Algorithm Reach the Fixed Point?

The **height of a lattice h** is the length of the longest path from Top to Bottom in the lattice.

![](./figs/04_lattice_height.png)

å¸Œæœ›æ±‚å–ï¼šThe maximum iterations **i** needed to reach the fixed point.

é¢„è®¾æ¡ä»¶ï¼šIn each iteration, assume only **one step in the lattice** (upwards or downwards) is made in **one node** (e.g., one 0 â†’ 1 in RD)

Assume the lattice height is h and the number of nodes in CFG is k.

**Result:** We need at most $i=h*k$ iterations.

**Problem 3:** When will the algorithm reach the fixed point, or when can we get the solution? 
- Worst case of #iterations: the product of the lattice height and the number of nodes in CFG

## May/Must Analysis, A Lattice View (è¿™ä¸ªéƒ¨åˆ†å¯ä»¥æ€»ç»“å‰è¿°çš„å†…å®¹)

æ— è®ºæ˜¯ May Analysis è¿˜æ˜¯ Must Analysisï¼Œéƒ½æ˜¯ä» unsafe result å‘ safe result è½¬å˜ï¼Œè€Œä¸”éƒ½æ˜¯ä» Precise å‘ Less Precise è½¬å˜

May Analysis ä»¥ Reaching Definitions ä¸¾ä¾‹ï¼Œä»¥æŸ¥é”™ä¸ºç›®æ ‡ï¼Œåœ¨ Bottom å’Œ Top ä¹‹é—´å­˜åœ¨ä¸€ä¸ª Truthï¼Œè¿›è€Œåˆ†å‰²äº† Safe å’Œ Unsafe çš„è¾¹ç•Œ

Must Analysis æ˜¯ä»¥ä¼˜åŒ–ä½œä¸ºç›®æ ‡

![](./figs/04_lattice_view.png)

**Another view to explain greatest/least fixed point? (minimal step by meet/join)**

May Analysis æœ¬èº«æ˜¯å–å¾—æœ€å°çš„ä¸Šç•Œï¼Œä¸å‰é¢çš„ä¸€å°æ­¥ä¸€å°æ­¥æ‰§è¡Œæ˜¯åŒç†çš„

Least Upper Bound ä¹Ÿå°±æ˜¯æˆ‘ä»¬èƒ½æ‰¾åˆ°çš„æœ€å°çš„ Fixed Point.

## Distributivity and MOP

### How Precise Is Our Solution?

**Meet-Over-All-Paths Solution (MOP)**

![](./figs/04_precise_solution.png)

MOP computes the data-flow values at the end of each path and apply join / meet operator to these values to find their lub / glb

- Some paths may be **not executable** ğŸ‘‰ **not fully precise**
- **Unbounded,** and **not enumerable** ğŸ‘‰ **impractical**

### Ours (Iterative Algorithm) vs. MOP 

![](./figs/04_ours_mop.png)

**Ours å’Œ MOP ä¹‹é—´å­˜åœ¨ä»€ä¹ˆåŒºåˆ«æˆ–è”ç³»ï¼Ÿ**

- Ours = F(x â¨† y)
- MOP = F(x) â¨† F(y)

<u>æ„é€ å…³ç³»</u>

By definition of lub â¨†, we have: x âŠ‘ x â¨† y and y âŠ‘ x â¨† y

As transfer function **F is monotonic**, we have: F(x) âŠ‘ F(x â¨† y) and F(y) âŠ‘ F(x â¨† y)

That means F(x â¨† y) is an upper bound of F(x) and F(y)

As F(x) â¨† F(y) is the lub of F(x) and F(y), we have F(x) â¨† F(y), we have: 

- F(x) â¨† F(y) âŠ‘ F(x â¨† y)
- MOP âŠ‘ Ours

**Ours is less precise than MOP.**

When **F is distributive,** i.e.,

- F(x) â¨† F(y) = F(x â¨† y)
- MOP = Ours

**(Ours is as precise as MOP)**

Bit-vector or Gen/Kill problems (set union / intersection for join / meet) are distributive.

## Constant Propagation

> ä¸æ»¡è¶³ `distributive` æ€§è´¨

Given a variable x at program point, determine whether x is **guaranteed** to hold a constant value at p.  **must analysis**ï¼Œä½†æ˜¯å’Œä¼ ç»Ÿçš„ must analysis ä¸å¤ªä¸€æ ·

- The OUT of each node in CFG, includes a set of pairs (x, v) where x is a variable and v is the value held by x after that node
- A data flow analysis framework (D, L, F) consists of:
  - D: a **direction** of data flow: forwards or backwards   ğŸ‘‰   Forward
  - L: a **lattice** including domain of the values V and a meet â¨… or join â¨† operator
  - F: a family of **transfer functions** from V to V

### Constant Propagation - Lattice

**Domain of the values V**

NAC = Not any Constant å³æ•´ä¸ªç¨‹åºæ²¡æœ‰ä»»ä½•ä¸€ä¸ªå¸¸é‡ï¼Œå³æ‰€æœ‰çš„éƒ½ä¸è¿›è¡Œä¼˜åŒ–ï¼Œå³æ˜¯USELESS

UNDEF å¦‚æœæŒ‰ç…§å¸¸è§„è€ƒè™‘ï¼Œæ˜¯æ‰€æœ‰çš„éƒ½æ˜¯å¸¸é‡ï¼Œä½†æ˜¯ç”±äºæ˜¯é€šè¿‡pairçš„æ–¹å¼è¡¨ç¤ºï¼Œç¨‹åºåˆå§‹åŒ–ä¸çŸ¥é“å€¼æ˜¯ä»€ä¹ˆï¼Œå› æ­¤åˆå§‹åŒ–ä¸º `UNDEF`

![](./figs/04_domain_constant_propagation.png)

**Meet Operator â¨…**

NAC â¨… v = NAC  å› ä¸ºæ˜¯safeï¼Œå› æ­¤ä¸€å®š

UNDEF â¨… v = v å³è¿›è¡Œäº†èµ‹å€¼çš„æ“ä½œã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼š**Uninitialized variables are not the focus in our constant propagation analysis**

c â¨… v = ?  éœ€è¦åˆ†ä¸ºä¸¤ç§æƒ…å†µ
- c â¨… c = c
- $c_1$ â¨… $c_2$ = NAC

At each path confluence (è·¯å¾„æ±‡åˆ) PC, we should apply `meet` for all variables in the incoming data-flow values at that PC.

### Constant Propagation - Transfer Function

Given a statement s: x = ..., we define its transfer function F as: **F:** OUT[s] = gen âˆª (IN[s] - {(x, _)})

_ è¡¨ç¤º x åŸæ¥æ‰€æœ‰çš„å€¼éƒ½ä¼šè¢«å¹²æ‰ï¼Œå› ä¸º x è¢«é‡æ–°èµ‹å€¼

(we use val(x) to denote the lattice value that variable x holds)

```java
- s: x=c; // c is a constant ğŸ‘‰ gen = {(x, c)}
- s: x=y; // ğŸ‘‰ gen = {(x, val(y))}
- s: x=y op z; // gen = {(x, f(y, z))}

f(y, z) = 
- val(y) op val(z) // if val(y) and val(z) are constants
- NAC // if val(y) or val(z) is NAC
- UNDEF // otherwise
```

undefineåœ¨Lé‡Œæ˜¯topï¼Œå…¶ä»–å¸¸é‡â‰¤undefï¼Œè‹¥undefçš„ä¸€ä¸ªå‡½æ•°è¾“å‡ºæ˜¯å¸¸é‡ï¼Œåˆ™è¿™ä¸ªå¸¸é‡å¯èƒ½å°äºå…¶ä»–å¸¸é‡çš„å‡½æ•°çš„è¾“å‡ºç»“æœï¼Œå¯¼è‡´gen(undef)â‰¤gen(c) ä¸æ»¡è¶³å•è°ƒæ€§

if **s** is not an assignment statement, **F** is the identity function.

### Constant Propagation - Nondistributivity

![](./figs/04_constant_propagation_nondistributivity.png)

F(X â¨… Y) åœ¨æ›´ä¸‹é¢çš„ä½ç½®ï¼Œå› æ­¤æ˜¯ä¸Šè¿°çš„å…³ç³»

## Worklist Algorithm

Worklist Algorithm, an optimization of Iterative Algorithm

**OUT will not change if IN does not change.**

```java
OUT[entry] = âŒ€;

for (each basic block B\entry)
  OUT[B] = âŒ€;

Worklist â† all basic blocks

while (Worklist is not empty) 
  Pick a basic block B from Worklist
  old_OUT = OUT[B]
  IN[B] = â¨† _ {P a predecessor of B} OUT[P];
  OUT[B] = gen_B âˆª (IN[B] - kill_B);

  if (old_OUT â‰  OUT[B]) 
    Add all successors of B to Worklist
```

## Problem

- Understand the functional view of iterative algotrithm
- The definitions of lattice and complete lattice
- Understand the fixed-point theorem
- How to summarize may and must analyses in lattices
- The relation between MOP and the solution produced by the iterative algorithm
- Constant propagation analysis
- Worklist algorithm